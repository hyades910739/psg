{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "import urllib\n",
    "import os\n",
    "from os.path import join\n",
    "import certifi\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先找到網址\n",
    "def geturl(start,end):\n",
    "    dic = {}  #建字典 蒐集 標題:網址\n",
    "    reg = re.compile(\"公告|<.+>\")  #把公告弄掉\n",
    "    while start>end:\n",
    "        url = \"https://www.ptt.cc/bbs/sex/index{}.html\".format(start)#把網址編號format進去\n",
    "        web=requests.get(url,cookies={'over18': '1'})\n",
    "        doc = BeautifulSoup(web.text, 'html.parser')   #傳入網址及cookies  doc為網頁原始碼\n",
    "        #防呆措施(異常處理)\n",
    "        if doc.select('title')[0].text=='500 - Internal Server Error' or doc.text=='404 page not found\\n':\n",
    "            print(url,\"is wrong page\")\n",
    "              \n",
    "        #print(doc)\n",
    "        for i in doc.select(\".r-ent .title\"):\n",
    "            if len(i.find_all('a'))>0:  #找出有網址的 避開已刪除貼文\n",
    "                info=i.find_all('a')\n",
    "                title=info[0].text\n",
    "                link0=info[0].get('href')\n",
    "                link='https://www.ptt.cc'+link0\n",
    "                if not reg.findall(title) and link: #如果title不是公告(compile)或<>\n",
    "                    dic[title] = link #在字典裡加 title link\n",
    "        start = start-1\n",
    "                \n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_url(url,path,push_filter=None):\n",
    "    # make dir:\n",
    "    try:\n",
    "        os.mkdir(path) #創建目錄\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    #pyquery\n",
    "    web=requests.get(url,cookies={'over18': '1'})\n",
    "    doc = BeautifulSoup(web.text, 'html.parser')\n",
    "    \n",
    " \n",
    "    #push_filter:\n",
    "    if push_filter:\n",
    "        push_number=0\n",
    "        for i in  doc.select(\"span.push-tag\"):\n",
    "            text=i.text\n",
    "            if text==\"推 \":              #計算推數\n",
    "                push_number+=1\n",
    "        if push_number<push_filter:   #span開頭 push-tag結尾\n",
    "            return None  #如果推數回傳小於指定值 就回傳none\n",
    "    \n",
    "    \n",
    "    #fild img url:\n",
    "    re_img = re.compile(\"htt.+imgur.+[jpg|jpeg]{0,1}\")  #找圖的縮網址\n",
    "    re_jpg = re.compile(\".jp.*g$\")  #找jp_g結尾\n",
    "    content = doc.select(\"#main-content\")[0].text.split(\"發信站: 批踢踢實業坊(ptt.cc)\")[0]  #把正文的文字抓下來 (正文也就是在批踢踢實業坊以前)\n",
    "    imgs = re_img.findall(content)  #從正文中找縮圖網址\n",
    "    if not imgs:  #如果沒東西 返回0\n",
    "        return 0\n",
    "    \n",
    "    # create folder\n",
    "    title = doc.select(\"title\")[0].text.split(\" - \")[0]   #找出標題 因為\" - \"後面是看板分類\n",
    "    #cut all symbols:\n",
    "    title = \"\".join(re.findall(\"[\\u4e00-\\u9fa5_a-zA-Z0-9]\",title)) #把中括號刪掉\n",
    "    # make dir for imgs:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(path, title)) #在path下用title名建資料夾\n",
    "    except FileExistsError:   #如果資料夾名重複的話\n",
    "        for i in range(100):\n",
    "            try:\n",
    "                os.mkdir(os.path.join(path, title+str(i+1))) #就把檔名改成title+數字(從1開始)\n",
    "            except:\n",
    "                pass #重回try繼續試\n",
    "            else:\n",
    "                break \n",
    "    ##  \n",
    "    try:\n",
    "        for num,img in enumerate(imgs): #enumerate 列出數據及數據index(預設為0)\n",
    "            if not re_jpg.findall(img): #如果網址後面不是jp_g結尾\n",
    "                img = img+\".jpg\"\n",
    "            if not re.findall(\"i\\.imgur\",img):  #如果img找不到i\\.imgur\n",
    "                img = \"i.imgur\".join(img.split(\"imgur\"))\n",
    "            name = \"img\"+str(num+1)+\".jpg\"  #取檔名\n",
    "\n",
    "            http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "            http.request('GET', img)   #請求驗證 不然會SLE error 或insecurewarning\n",
    "            request = requests.get(img)\n",
    "            local_path = 'C:/Users/Guan-Ting Chen/'+path+\"/\"+title+\"/\"+name\n",
    "            #改用open下載 避免用request.urlretrivey造成unicode error\n",
    "            with open(local_path, 'wb') as file:    #把圖載下來 丟進title的資料夾取名為nmae\n",
    "                file.write(request.content)\n",
    "\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"url : \",url)\n",
    "        print(\"title\",title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler(start,end,path,push_filter=None) :\n",
    "    res= geturl(start,end)\n",
    "    for url in res.values():\n",
    "        get_img_url(url,path,push_filter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler(3800,3798,\"gog\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/sex/index38000.html is wrong page\n",
      "https://www.ptt.cc/bbs/sex/index37999.html is wrong page\n"
     ]
    }
   ],
   "source": [
    "#如果網址亂輸入\n",
    "#超出現有數字\n",
    "crawler(38000,37998,\"gog\",10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
